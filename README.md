# ğŸ“Š Regulatory Reporting Simulation

â€¢ Simulated US regulatory reports (Y-9C, Y-14, 2052a) using SQL in Azure Data Studio to map financial data to compliance reporting
formats.

â€¢ Stored and transformed synthetic banking data in Hadoop HDFS to enable scalable data preparation and validation workflows.

---

## ğŸš€ Overview

This project replicates the process of transforming financial datasets into standardized regulatory reports using:

- SQL scripting in **Azure Data Studio**
- Scalable processing with **Apache Spark (PySpark)**
- A local simulation of **Hadoop HDFS**

---

## ğŸ› ï¸ Tools & Technologies

- **Azure Data Studio** â€“ SQL-based data generation
- **Apache Spark (PySpark)** â€“ Distributed data processing
- **Python 3.10+**
- **Simulated HDFS** â€“ Folder-based structure for Hadoop-like workflow

---

## ğŸ“ Folder Structure

RegulatoryReporting/
â”œâ”€â”€ spark_processing/ # PySpark scripts for report generation
â”œâ”€â”€ sql_scripts/ # SQL script to generate synthetic financial data
â”œâ”€â”€ simulated_hdfs/
â”‚ â””â”€â”€ user/bank/
â”‚ â”œâ”€â”€ raw_data/ # Input CSVs (accounts, loans, liquidity)
â”‚ â””â”€â”€ output_data/ # Generated reports (Y9C, Y14, 2052a)
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ .gitignore # Ignore raw/output folders and environment files
â””â”€â”€ README.md # This documentation


---

## â–¶ï¸ How to Run the Project

1. **Prepare Data**  
   Export SQL output to CSVs and place them inside:
simulated_hdfs/user/bank/raw_data/


### 2. **Activate Environment**
```bash
conda activate spark-env




âœ… Sample Reports Generated
Y-9C Summary â€“ Total balances by account type

Y-14 Summary â€“ Risk-weighted balances by loan type

FR 2052a Summary â€“ Net liquidity flow by source type


